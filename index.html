<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Emotion Detection — Demo</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;background:#f8fafc}
    .video-wrap{position:relative;border-radius:12px;overflow:hidden}
    #overlay{position:absolute;left:0;top:0}
    .emotion-badge{font-weight:700;padding:.5rem 1rem;border-radius:999px}
    .pulse{animation:pulse 1.6s infinite}
    @keyframes pulse{0%{transform:scale(1)}50%{transform:scale(1.03)}100%{transform:scale(1)}}
    .bar{height:10px;border-radius:6px;background:#e9ecef;overflow:hidden}
    .bar-fill{height:100%;border-radius:6px}
    .fade-in{animation:fadeInUp .5s ease both}
    @keyframes fadeInUp{from{opacity:0;transform:translateY(8px)}to{opacity:1;transform:none}}
  </style>
</head>
<body>
  <nav class="navbar navbar-expand-lg navbar-white bg-white shadow-sm mb-4">
    <div class="container-fluid">
      <a class="navbar-brand fw-bold" href="#">Emotion Detection</a>
      <div class="small text-muted d-none d-md-block">Webcam demo • client-only • face-api.js</div>
    </div>
  </nav>

  <main class="container">
    <div class="row g-4">
      <section class="col-lg-7">
        <div class="card shadow-sm mb-3">
          <div class="card-body">
            <h5 class="card-title">Live camera</h5>
            <div class="video-wrap mt-3">
              <video id="video" width="100%" autoplay muted playsinline style="background:#000;border-radius:8px"></video>
              <canvas id="overlay"></canvas>
            </div>
            <div class="d-flex gap-2 mt-3">
              <button id="startBtn" class="btn btn-primary">Start</button>
              <button id="stopBtn" class="btn btn-outline-secondary" disabled>Stop</button>
              <button id="snapBtn" class="btn btn-outline-success" disabled>Snapshot</button>
              <button id="downloadReport" class="btn btn-outline-secondary ms-auto" disabled>Download Report</button>
            </div>
            <div class="mt-3 small text-muted">Note: This demo uses <em>face-api.js</em> expression detection. Models are loaded from a public CDN — for production host model files yourself.</div>
          </div>
        </div>
      </section>

      <aside class="col-lg-5">
        <div class="card shadow-sm mb-3 fade-in">
          <div class="card-body">
            <h6>Detected emotion</h6>
            <div class="d-flex align-items-center gap-3 mt-2">
              <div id="emotionLabel" class="emotion-badge bg-light text-dark">—</div>
              <div class="small text-muted">Confidence: <span id="emotionConfidence">0%</span></div>
            </div>
            <div class="mt-3">
              <h6 class="small-muted mb-2">Emotion probabilities</h6>
              <div id="probList" class="d-flex flex-column gap-2"></div>
            </div>
            <hr>
            <div>
              <h6 class="small-muted">History (last 20)</h6>
              <div id="historyList" style="max-height:220px;overflow:auto"></div>
            </div>
          </div>
        </div>

        <div class="card shadow-sm">
          <div class="card-body">
            <h6 class="mb-2">Model status</h6>
            <div id="modelStatus" class="small-muted">Not loaded</div>
            <div class="mt-3 small text-muted">If models fail to load, check your network or host model files locally. For production, download face-api models and serve from <code>/models</code>.</div>
          </div>
        </div>
      </aside>
    </div>
  </main>

  <!-- face-api.js CDN -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <script>
    // -------- Configuration --------
    // Public CDN where models are hosted for demo. For production, host models yourself (e.g. /models).
    const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';

    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const snapBtn = document.getElementById('snapBtn');
    const downloadReport = document.getElementById('downloadReport');

    const emotionLabel = document.getElementById('emotionLabel');
    const emotionConfidence = document.getElementById('emotionConfidence');
    const probList = document.getElementById('probList');
    const historyList = document.getElementById('historyList');
    const modelStatus = document.getElementById('modelStatus');

    let stream = null; let running = false; let intervalId = null; let history = [];

    // load models
    async function loadModels(){
      modelStatus.textContent = 'Loading models...';
      try{
        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
        await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
        modelStatus.textContent = 'Models loaded';
      }catch(err){ console.error(err); modelStatus.textContent = 'Model load failed: ' + err.message; alert('Failed to load models. Check network or host models locally.'); }
    }

    // start camera
    async function startCamera(){
      try{
        stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio:false });
        video.srcObject = stream;
        await video.play();
        overlay.width = video.videoWidth; overlay.height = video.videoHeight;
        running = true; startDetection();
        startBtn.disabled = true; stopBtn.disabled = false; snapBtn.disabled = false; downloadReport.disabled = false;
      }catch(err){ console.error(err); alert('Camera access denied or not available.'); }
    }

    function stopCamera(){
      running = false; if(intervalId) clearInterval(intervalId); if(stream){ stream.getTracks().forEach(t=>t.stop()); stream=null; }
      ctx.clearRect(0,0,overlay.width, overlay.height);
      startBtn.disabled = false; stopBtn.disabled = true; snapBtn.disabled = true;
    }

    // detection loop
    function startDetection(){
      intervalId = setInterval(async ()=>{
        if(video.paused || video.ended) return;
        const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
        ctx.clearRect(0,0,overlay.width, overlay.height);
        if(detections){
          const {expressions, detection} = detections;
          // draw box
          const box = detection.box;
          ctx.lineWidth = 2; ctx.strokeStyle = '#0d6efd'; ctx.strokeRect(box.x, box.y, box.width, box.height);
          // process expressions
          const sorted = Object.entries(expressions).sort((a,b)=>b[1]-a[1]);
          const dominant = sorted[0];
          const label = dominant[0]; const conf = dominant[1];
          showEmotion(label, conf, expressions);
        } else {
          showNoFace();
        }
      }, 200); // every 200ms
    }

    function showEmotion(label, conf, expressions){
      const pct = Math.round(conf*100);
      emotionLabel.textContent = label.toUpperCase();
      emotionLabel.className = 'emotion-badge bg-light text-dark pulse';
      emotionConfidence.textContent = pct + '%';

      // probabilities list
      probList.innerHTML = '';
      const ordered = Object.entries(expressions).sort((a,b)=>b[1]-a[1]);
      ordered.forEach(([k,v])=>{
        const row = document.createElement('div'); row.className='mb-2';
        const name = document.createElement('div'); name.className='small-muted mb-1 text-capitalize'; name.textContent = k;
        const bar = document.createElement('div'); bar.className='bar'; const fill = document.createElement('div'); fill.className='bar-fill'; fill.style.width = Math.round(v*100) + '%'; fill.style.background = emotionColor(k);
        bar.appendChild(fill); row.appendChild(name); row.appendChild(bar); probList.appendChild(row);
      });

      // history
      history.unshift({label, conf, at: Date.now()}); if(history.length>20) history.pop(); renderHistory();
    }

    function emotionColor(name){ switch(name){ case 'happy': return '#ffc107'; case 'sad': return '#0d6efd'; case 'angry': return '#dc3545'; case 'surprised': return '#6610f2'; case 'neutral': return '#6c757d'; case 'disgusted': return '#20c997'; case 'fearful': return '#0dcaf0'; default: return '#adb5bd'; } }

    function showNoFace(){ emotionLabel.textContent = 'No face'; emotionLabel.className='emotion-badge bg-light text-muted'; emotionConfidence.textContent = '—'; probList.innerHTML = ''; }

    function renderHistory(){ historyList.innerHTML = ''; history.forEach(h=>{ const d = new Date(h.at); const el = document.createElement('div'); el.className='d-flex justify-content-between align-items-center py-1 border-bottom'; el.innerHTML = `<div class="text-capitalize">${h.label}</div><div class="small-muted">${Math.round(h.conf*100)}% • ${d.toLocaleTimeString()}</div>`; historyList.appendChild(el); }); }

    // snapshot
    document.getElementById('snapBtn').addEventListener('click', ()=>{
      if(!video || video.videoWidth===0) return alert('No video');
      const c = document.createElement('canvas'); c.width = video.videoWidth; c.height = video.videoHeight; const x = c.getContext('2d'); x.drawImage(video,0,0); // overlay not drawn
      const url = c.toDataURL('image/png'); const a = document.createElement('a'); a.href = url; a.download = 'snapshot.png'; a.click();
    });

    // download report
    document.getElementById('downloadReport').addEventListener('click', ()=>{
      const report = { generated: new Date().toISOString(), history };
      const blob = new Blob([JSON.stringify(report,null,2)],{type:'application/json'}); const url = URL.createObjectURL(blob); const a = document.createElement('a'); a.href = url; a.download = 'emotion-report.json'; a.click(); URL.revokeObjectURL(url);
    });

    // start/stop handlers
    startBtn.addEventListener('click', async ()=>{ startBtn.disabled = true; modelStatus.textContent = 'Loading models...'; await loadModels(); modelStatus.textContent = 'Models loaded'; await startCamera(); });
    stopBtn.addEventListener('click', ()=>{ stopCamera(); });

    // auto-load models silently (optional)
    loadModels();
  </script>
</body>
</html>
